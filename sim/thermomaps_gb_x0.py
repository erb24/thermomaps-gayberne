# -*- coding: utf-8 -*-
"""thermomaps_GB_x0.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1mPDicRFgMdNHEe6xpgwLGRzpr9TxOyG_

<a href="https://colab.research.google.com/github/lherron2/thermomaps-ising/blob/main/thermomaps_ising.ipynb" target="_parent"><img src="https://colab.research.google.com/assets/colab-badge.svg" alt="Open In Colab"/></a>
"""


import numpy as np
from tqdm import tqdm

from ising.observables import Energy, Magnetization
from ising.samplers import SwendsenWangSampler, SingleSpinFlipSampler
from ising.base import IsingModel

from data.trajectory import EnsembleTrajectory, MultiEnsembleTrajectory
from data.dataset import MultiEnsembleDataset
from data.generic import Summary

from tm.core.prior import GlobalEquilibriumHarmonicPrior, UnitNormalPrior
from tm.core.backbone import ConvBackbone
from tm.core.diffusion_model import DiffusionTrainer, SteeredDiffusionSampler
from tm.core.diffusion_process import VPDiffusion
from tm.architectures.unet_2d_mid_attn import Unet2D
from tm.architectures.unet_1d import Unet1D

# extra libraries I am importing to implement the kludge
from data.observables import Observable
from sklearn.model_selection import ShuffleSplit
from tm.core.loader import Loader

"""First we simulate the Ising model over a range of temperatures, recording a `trajectory` consisting of lattice configurations. These trajectories are then aggregated into a `MultiEnsembleDataset` (i.e. many trajectories gathered under different thermodynamic ensembles)."""

trajectories = []
for temperature in [0.1, 0.5, 1.0, 1.1, 1.2, 1.3, 1.4, 1.5, 1.6, 1.7, 1.8, 1.9, 2.0, 2.1, 2.2, 2.3, 2.4]:
    IM = IsingModel(sampler=SingleSpinFlipSampler, size = 8, warmup = 1000, temp = np.round(temperature,1), Jx = 1, Jy = 1)
    IM.trajectory.coordinates = np.load('drive/MyDrive/%sT/local_S.npy' % temperature)[1000:,:320]
    IM.trajectory.summary.size = 343
    IM.trajectory.summary.name = 'Gay-Berne'
    nrg = np.load('drive/MyDrive/%sT/e.npy' % temperature)[1000:]
    S = np.load('drive/MyDrive/%sT/S.npy' % temperature)[1000:]
    IM.trajectory.observables['energy'] = nrg
    IM.trajectory.observables['magnetization'] = S
    trajectories.append(IM.trajectory)
dataset = MultiEnsembleDataset(trajectories, Summary())

"""
Each of the trajectories has a `Summary` object attached to it, which is just a `dict` containing metadata about the trajectory. If the summaries associated with all the trajectories in the `MultiEnsembleDataset` all have the same keys, the contents of the `MultiEnsembleDataset` can be conveniently cast as a pandas dataframe."""

# for me, I think I need to pass directly to the TM model the
# trajectories of the local nematic/S/P2 order parameter calculated for
# each ellipsoid in the simulation box. These map directly onto the Ising
# spins used here, and

df = dataset.to_dataframe()

"""The dataframe representation is especially powerful for creating subsets of a `MultiEnsembleDataset`. In this cell we extract a sub-dataframe containing trajectories at temperatures `T=1.5` and `T=2.5`. The sub-dataset can be initialized from the restricted dataframe.

**Our training data is going to be 5,000 samples from two temperatures (total of 10,000 samples) asymetrically spaced about the critical temperature $T_c \approx 2.26$**
"""

sub_df = df[df['temperature'].isin([1.0,1.5, 2.2])]
sub_dataset = dataset.from_dataframe(sub_df)

"""Here we extract the relevant observables for the ising model from each temperature in the dataset and plot the distribution of magnetization and energy as a function of temperature."""

simulated_M_v_T_mean = {t.state_variables['temperature']: t.observables['magnetization'].mean() for t in dataset.trajectories}
simulated_E_v_T_mean = {t.state_variables['temperature']: t.observables['energy'].mean() for t in dataset.trajectories}
simulated_M_v_T_std = {t.state_variables['temperature']: t.observables['magnetization'].std() for t in dataset.trajectories}
simulated_E_v_T_std = {t.state_variables['temperature']: t.observables['energy'].std() for t in dataset.trajectories}

train_M_v_T = {traj.state_variables['temperature']: simulated_M_v_T_mean[traj.state_variables['temperature']] for traj in sub_dataset.trajectories}
train_E_v_T = {traj.state_variables['temperature']: simulated_E_v_T_mean[traj.state_variables['temperature']] for traj in sub_dataset.trajectories}


# no fluctuations; just a single, averaged observable calculated over the simulation trajectory
for traj in sub_dataset.trajectories:
    print(traj.state_variables['temperature'])

"""Loaders for ThermoMap data can also be constructed from a `MultiEnsembleDataset`. The coordinates of the trajectory object are joined with the specified `state_variables` along the channel dimension."""

# need to change to a one-dimensional Ising model
train_loader, test_loader = sub_dataset.to_TMLoader(train_size=0.8, test_size=0.2, state_variables=['temperature'], dequantize = False)

"""Here we initialize the components of the ThermoMap algorithm.

First, we initialize the prior distribution that samples from the dataset will be mapped onto. The `GlobalEquilibriumHarmonicPrior` (`GEHP`) implements the temperature scaling at the core of the ThermoMap algorithm. We view the prior distribution as the equilibrium distribution arising from dynamics of a *physical* prior system. The `GEHP` assumes that the prior system is a particle in a harmonic trap, which results in a Normal equilibrium distribution whose variance is proportional to temperature.

I have also provided a `UnitNormalPrior` (`UNP`) which is a drop-in replacement for the `GEHP` that does not include any temperature rescaling. As such, a ThermoMap trained with a `UNP` is a standard diffusion model.

The prior requires the shape of the training data as input as well as the channels that are associated with coordinates and fluctuations (i.e. temperatures). The coordinate dimensions are sampled from a Normal distribution with variance determined by the fluctuation dimensions, while the fluctuation channels are sampled from a unit Normal distribution.
"""

prior = GlobalEquilibriumHarmonicPrior(shape=train_loader.data.shape, channels_info={"coordinate": [0], "fluctuation": [1]})

"""The `model` is the black-box that is used to parameterize the score. Here we opt for a 2D U-net with attention at the upsampling/downsampling bottleneck."""

model = Unet1D(dim=16, dim_mults=(1, 2, 4, 8), resnet_block_groups=8, channels=2)

"""The `backbone` is a wrapper around the model which contains the optimizer, scheduler, and other utilities and implements saving and loading the `model`."""

backbone = ConvBackbone(model=model,
                        data_shape=train_loader.data_dim,
                        target_shape=320,
                        num_dims=3,
                        lr=1e-5,
                        eval_mode="train",
                       interpolate=False,
                        self_condition=True)

"""The `diffusion` instantiates the noise schedule, and implements the forward and reverse transition kernels of the diffusion process. Functionally, the `diffusion` implements the Euler-Maryuma SDE/Euler ODE solver for the variance-preserving diffusion process."""

diffusion = VPDiffusion(num_diffusion_timesteps=100)

"""The `trainer` implements the training algorithm, consisting of sampling noise from the `prior`, calls to the transition kernels of the `diffusion`, and parameterizing the `backbone` to match the score."""

trainer = DiffusionTrainer(diffusion,
                           backbone,
                           train_loader,
                           prior,
                           model_dir="/content/models", # save models every epoch
                           pred_type="x0", # set to "noise" or "x0"
                           test_loader=test_loader # optional
                           )

trainer.train(20, loss_type="smooth_l1", batch_size = 1024)
# Note that the test loss is usually slightly lower than the training loss. This is because
# the training loss is averaged over each epoch (which contains many updates to the weights
# via backprop) while the test loss is evaluated at the end of each epoch. Is there a
# better way to do this? Probably. But it's low priority at the moment.

"""The `sampler` is similar to the `trainer`, but rather than calling the $p(x_0|x_t)$ kernel, the `sampler` iteratively calls the $p(x_{t-1}|x_t)$ kernel."""

sampler = SteeredDiffusionSampler(diffusion,
                                  backbone,
                                  train_loader,
                                  prior,
                                  pred_type='x0', # must be the same as in DiffusionTrainer
                                  )

"""With our trained model, we generated samples at a range of different temperatures, store the coordinates in an `EnsembleTrajectory` object, and evaluate observables over the coordinates of the trajectory. Note that there is no temporal order between points in the trajectory, as was the case of the Ising simulator."""

backbone.load_model('drive/MyDrive/model.model/', 20)

backbone.save_state('x0_self_conditioned_lr1e-5_T2.2_model', 20)

trajectories = []
pbar = tqdm([0.1, 0.5, 1.0, 1.1, 1.2, 1.3, 1.5, 1.7, 1.8, 1.9, 2.0, 2.2, 2.4])
for temperature in pbar:
  pbar.set_description(f"Generating at T={temperature:.1f}")
  samples = sampler.sample_loop(num_samples=5000, batch_size=5000, temperature=temperature, gamma = 1.)
  coords = samples[:,0,:].numpy() # take coordinate dimension

  # store in trajectory
  trajectory = EnsembleTrajectory(summary=Summary(info="Generated trajectory"),
                                  state_variables=Summary(temperature=temperature),
                                  coordinates=coords)

  # evaluate observables over trajectory coordinates and add to trajectory object
  #energy = Energy()
  #energy.evaluate(trajectory.coordinates)

  mag = Magnetization()
  mag.evaluate(trajectory.coordinates)

  #trajectory.add_observable(energy)
  trajectory.add_observable(mag)
  trajectories.append(trajectory)

# store in trajectory
trajectory = EnsembleTrajectory(summary=Summary(info="Generated trajectory"),
                              state_variables=Summary(temperature=temperature),
                              coordinates=coords)


generated_M_v_T_mean = {t.state_variables['temperature']: t.observables['magnetization'].quantity.mean() for t in trajectories}
#generated_E_v_T_mean = {t.state_variables['temperature']: t.observables['energy'].quantity.mean() for t in trajectories}
generated_M_v_T_std = {t.state_variables['temperature']: t.observables['magnetization'].quantity.std() for t in trajectories}
#generated_E_v_T_std = {t.state_variables['temperature']: t.observables['energy'].quantity.std() for t in trajectories}
